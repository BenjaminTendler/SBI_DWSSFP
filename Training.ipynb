{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Import Packages\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "##\n",
    "#SBI Specific Packages\n",
    "import torch\n",
    "from sbi import analysis as analysis\n",
    "from sbi import utils as utils\n",
    "from sbi.inference import SNPE, NPE, MCMCPosterior, posterior_estimator_based_potential, simulate_for_sbi\n",
    "from sbi.utils import RestrictionEstimator\n",
    "from sbi.utils.user_input_checks import check_sbi_inputs, process_prior, process_simulator\n",
    "from sbi.analysis import conditional_corrcoeff, conditional_pairplot, conditional_potential, pairplot, pairplot\n",
    "from sbi.neural_nets.embedding_nets import FCEmbedding\n",
    "from sbi.neural_nets import posterior_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Import custom functions (Define your path)\n",
    "sys.path.append('YourPath')\n",
    "from FreedAnalytical import *\n",
    "from ImportData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Define Data Path and load data (Text files corresponding to acquisition parameters)\n",
    "DataPath = 'YourDataPath'\n",
    "_, _, _, _, _, _, bvecs, FlipAngles, tau, G, TRs = ImportDataDWSSFP(DataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Define Priors\n",
    "num_dim = 6\n",
    "prior = utils.BoxUniform(low=torch.tensor([0,0,0,-0.00025,-0.00025,-0.00025]) * torch.ones(num_dim), high=torch.tensor([0.0005,0.0005,0.0005,0.00025,0.00025,0.00025]) * torch.ones(num_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Define Simulator (encompass in lambda as it only accepts single input) - Note - simulator is conditioned on arbitrary T1, T2 & B1 values.\n",
    "simulator = lambda theta: FreedDWSSFPTensor_Conditional_SBIWrapper(theta,G,tau,TRs,FlipAngles,bvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Establish network to identify prior regions corresponding to invalid simulations (for diffusion tensor, where eigenvalues < 0) via a restriction estimator\n",
    "\n",
    "##\n",
    "#First Generate training data for the restriction estimator\n",
    "number_of_simulations = 500000\n",
    "theta_RestrictionEstimator, x_RestrictionEstimator = simulate_for_sbi(simulator, prior, number_of_simulations)\n",
    "\n",
    "##\n",
    "#Train Restricted Prior Estimator\n",
    "restriction_estimator = RestrictionEstimator(prior=prior)\n",
    "restriction_estimator.append_simulations(theta_RestrictionEstimator, x_RestrictionEstimator)\n",
    "classifier = restriction_estimator.train()\n",
    "\n",
    "##\n",
    "#Define Restricted Prior\n",
    "restricted_prior = restriction_estimator.restrict_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Perform forward simulations with restricted prior for SBI inference network\n",
    "number_of_simulations = 1000000\n",
    "theta, x = simulate_for_sbi(simulator, restricted_prior, number_of_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Create 5 different SNR levels for the training data (not including noise free simulations)\n",
    "Rounds = 5\n",
    "\n",
    "##\n",
    "#Estimate average Signal Amplitude of b0 data\n",
    "b0 = torch.nanmean(x[:,:-3][:,tau==0])\n",
    "#Define maximum and minimum SNR\n",
    "SNR = [2,50]\n",
    "\n",
    "##\n",
    "#Replicate the variable and signal arrays by the number of SNR levels\n",
    "thetaSNR = theta.repeat(Rounds+1,1)\n",
    "xSNR = x.repeat(Rounds+1,1)\n",
    "\n",
    "##\n",
    "#Scale the signals by the different SNR levels\n",
    "xSNR[theta.shape[0]:,:-3]=np.abs(xSNR[theta.shape[0]:,:-3]+torch.randn((x[:,:-3].shape[0]*Rounds,x[:,:-3].shape[1]))*b0/torch.distributions.uniform.Uniform(SNR[0], SNR[1]).sample([x.shape[0]*Rounds,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Define Neural Density Estimator\n",
    "neural_posterior = posterior_nn(model=\"nsf\")\n",
    "\n",
    "# setup the inference procedure with NPE and perform training\n",
    "inference = SNPE(prior=prior,density_estimator=neural_posterior)\n",
    "density_estimator = inference.append_simulations(thetaSNR, xSNR).train()\n",
    "posterior = inference.build_posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#Save Posterior module\n",
    "with open(\"YourPosterior.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(posterior, handle)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
